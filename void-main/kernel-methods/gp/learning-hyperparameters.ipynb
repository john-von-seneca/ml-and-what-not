{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random as rnd\n",
    "import os\n",
    "import math\n",
    "\n",
    "# required for interactive plotting\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "import numpy.polynomial as np_poly\n",
    "\n",
    "from IPython.display import Math\n",
    "from IPython.display import Latex\n",
    "from IPython.display import HTML\n",
    "\n",
    "from pprint import pprint\n",
    "import functools as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialization\n",
    "$\n",
    "\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\n",
    "\\newcommand{\\Bracket}[1]{\\left[#1\\right]}\n",
    "\\newcommand{\\cases}[1]{\\begin{cases}#1\\end{cases}}\n",
    "\\newcommand{\\cov}[1]{\\text{cov} \\sigma\\left[#1\\right]}\n",
    "\\newcommand{\\diff}[2]{\\frac{d #1}{d #2}}\n",
    "\\newcommand{\\difftwo}[2]{\\frac{d^2 #1}{d {#2}^2}}\n",
    "\\newcommand{\\diffn}[2]{{#1}^{\\prime}(#2)}\n",
    "\\newcommand{\\E}[1]{\\mathbb{E}\\left[ #1 \\right]}\n",
    "\\newcommand{\\expb}[1]{\\exp\\left\\{#1\\right\\}} \n",
    "\\newcommand{\\EXP}[1]{\\exp\\left\\{#1\\right\\}} \n",
    "\\newcommand{\\frachalf}[1]{\\frac{#1}{2}~}\n",
    "\\newcommand{\\fracone}[1]{\\frac{1}{#1}~}\n",
    "\\newcommand{\\fracrec}[1]{\\frac{1}{#1}~}\n",
    "\\newcommand{\\half}{\\fracone{2}}\n",
    "\\newcommand{\\H}[1]{\\mathbb{H}\\left[#1\\right]}\n",
    "\\newcommand{\\Int}[2]{\\displaystyle \\int_{#1}^{#2}~}\n",
    "\\newcommand{\\intinfinf}{\\Int{-\\infty}{\\infty}}\n",
    "\\newcommand{\\inv}[1]{#1^{-1}}\n",
    "\\newcommand{\\invp}[1]{\\left({#1}\\right)^{-1}}\n",
    "\\newcommand{\\KL}[2]{\\text{KL}\\left(#1 \\Vert #2\\right)}\n",
    "\\newcommand{\\Lim}[1]{\\displaystyle \\lim_{#1}}\n",
    "\\newcommand{\\Ln}[1]{\\ln \\left\\(#1\\right\\)}\n",
    "\\newcommand{\\Lnb}[1]{\\ln \\left\\{#1\\right\\} }\n",
    "\\newcommand{\\Mod}[1]{\\left|#1\\right|}\n",
    "\\newcommand{\\Norm}[1]{\\left\\lVert #1 \\right\\rVert}\n",
    "\\newcommand{\\Normsqr}[1]{\\Norm{#1}^2}\n",
    "\\newcommand{\\map}[1]{#1_{\\text{MAP}}}\n",
    "\\newcommand{\\ml}[1]{#1_{\\text{ML}}}\n",
    "\\newcommand{\\MI}[1]{\\mathcal{I}\\left(#1\\right)}\n",
    "\\newcommand{\\P}{\\mathbb{P}}\n",
    "\\newcommand{\\Paran}[1]{\\left(#1\\right)}\n",
    "\\newcommand{\\Partial}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\sqrbrkt}[1]{\\Bracket{#1}^2}\n",
    "\\newcommand{\\sqrbrc}[1]{\\Brace{#1}^2}\n",
    "\\newcommand{\\trace}[1]{\\text{Tr}\\left( #1 \\right)}\n",
    "\\newcommand{\\traceb}[1]{\\text{Tr}\\left\\{#1\\right\\}}\n",
    "\\newcommand{\\underl}[1]{\\text{$\\underline{#1}$}}\n",
    "\\newcommand{\\V}[1]{\\mathbb{V}\\left[#1\\right]}\n",
    "$\n",
    "$\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\mat}[1]{ \\left[ \\begin{matrix} #1 \\end{matrix} \\right] }\n",
    "\\newcommand{\\matp}[1]{ \\left( \\begin{matrix} #1 \\end{matrix} \\right)}\n",
    "\\newcommand{\\mats}[1]{ \\begin{matrix}#1\\end{matrix} }\n",
    "\\newcommand{\\arrthree}[1]{\n",
    "\\begin{array}{rlr} #1 \\end{array}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\newcommand{\\C}{\\mathbb{C}}\n",
    "\\newcommand{\\Ca}{\\mathcal{C}}\n",
    "\\newcommand{\\Caone}{\\Ca_1}\n",
    "\\newcommand{\\Catwo}{\\Ca_2}\n",
    "\\newcommand{\\Cak}{\\Ca_k}\n",
    "\\newcommand{\\D}{\\mathcal{D}}\n",
    "\\newcommand{\\G}{\\mathcal{G}}\n",
    "\\newcommand{\\I}{\\mathcal{I}}\n",
    "\\newcommand{\\L}{\\mathcal{L}}\n",
    "\\newcommand{\\M}{\\mathcal{M}}\n",
    "\\newcommand{\\N}{\\mathbb{N}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\Ra}{\\mathcal{R}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\commentgray}[1]{\\color{gray}{\\text{#1}}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum, product\n",
    "$\n",
    "\\newcommand{\\sumi}{\\displaystyle \\sum_i}\n",
    "\\newcommand{\\sumiD}{\\displaystyle \\sum_{i=1}^{D}}\n",
    "\\newcommand{\\sumiL}{\\displaystyle \\sum_{i=1}^{L}}\n",
    "\\newcommand{\\sumiN}{\\displaystyle \\sum_{i=1}^{N}}\n",
    "\\newcommand{\\sumjD}{\\displaystyle \\sum_{j=1}^{D}}\n",
    "\\newcommand{\\sumjK}{\\displaystyle \\sum_{j=1}^{K}}\n",
    "\\newcommand{\\sumjMl}{\\sum_{j=1}^{M-1}}\n",
    "\\newcommand{\\sumkK}{\\displaystyle \\sum_{k=1}^{K}}\n",
    "\\newcommand{\\sumkM}{\\displaystyle \\sum_{k=1}^{M}}\n",
    "\\newcommand{\\sumkMl}{\\sum_{k=1}^{M-1}}\n",
    "\\newcommand{\\summN}{\\displaystyle \\sum_{m=1}^{N}}\n",
    "\\newcommand{\\sumnN}{\\displaystyle \\sum_{n=1}^{N}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\prodi}{\\displaystyle \\prod_i}\n",
    "\\newcommand{\\prodiD}{\\displaystyle \\prod_{i=1}^{D}}\n",
    "\\newcommand{\\prodiL}{\\displaystyle \\prod_{i=1}^{L}}\n",
    "\\newcommand{\\prodiN}{\\displaystyle \\prod_{i=1}^{N}}\n",
    "\\newcommand{\\prodjK}{\\displaystyle \\prod_{j=1}^{K}}\n",
    "\\newcommand{\\prodkK}{\\displaystyle \\prod_{k=1}^{K}}\n",
    "\\newcommand{\\prodmN}{\\displaystyle \\prod_{m=1}^{N}}\n",
    "\\newcommand{\\prodnN}{\\displaystyle \\prod_{n=1}^{N}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alphabet shortcuts\n",
    "$\n",
    "\\newcommand{\\ab}{\\mathbf{a}}\n",
    "\\newcommand{\\at}{\\ab^T}\n",
    "\\newcommand{\\Ab}{\\mathbf{A}}\n",
    "\\newcommand{\\At}{\\Ab^T}\n",
    "\\newcommand{\\Ai}{\\inv{\\Ab}}\n",
    "\\newcommand{\\Abjk}{\\Ab_{jk}}\n",
    "\\newcommand{\\bb}{\\mathbf{b}}\n",
    "\\newcommand{\\bt}{\\bb^T}\n",
    "\\newcommand{\\Bb}{\\mathbf{B}}\n",
    "\\newcommand{\\Bt}{\\Bb^T}\n",
    "\\newcommand{\\Cb}{\\mathbf{C}}\n",
    "\\newcommand{\\Cn}{\\Cb_{N}}\n",
    "\\newcommand{\\Db}{\\mathbf{D}}\n",
    "\\newcommand{\\fb}{\\mathbf{f}}\n",
    "\\newcommand{\\fp}{f^{\\prime}}\n",
    "\\newcommand{\\Hb}{\\mathbf{H}}\n",
    "\\newcommand{\\hx}{h(\\xb)}\n",
    "\\newcommand{\\Jb}{\\mathbf{J}}\n",
    "\\newcommand{\\kb}{\\mathbf{k}}\n",
    "\\newcommand{\\kt}{\\kb^T}\n",
    "\\newcommand{\\Kb}{\\mathbf{K}}\n",
    "\\newcommand{\\Lb}{\\mathbf{L}}\n",
    "\\newcommand{\\Lt}{\\Lb^T}\n",
    "\\newcommand{\\Lbi}{\\Lb^{-1}}\n",
    "\\newcommand{\\mb}{\\mathbf{m}}\n",
    "\\newcommand{\\mt}{\\mb^T}\n",
    "\\newcommand{\\mbn}{\\mb_N}\n",
    "\\newcommand{\\mbnt}{\\mbn^T}\n",
    "\\newcommand{\\mbN}{\\mb_N}\n",
    "\\newcommand{\\mbNt}{\\mbn^T}\n",
    "\\newcommand{\\Mb}{\\mathbf{M}}\n",
    "\\newcommand{\\Qb}{\\mathbf{Q}}\n",
    "\\newcommand{\\Rb}{\\mathbf{R}}\n",
    "\\newcommand{\\sb}{\\mathbf{s}}\n",
    "\\newcommand{\\Sb}{\\mathbf{S}}\n",
    "\\newcommand{\\tb}{\\mathbf{t}}\n",
    "\\newcommand{\\tbnn}{\\tb_{N}}\n",
    "\\newcommand{\\tbnp}{\\tb_{N+1}}\n",
    "\\newcommand{\\tt}{\\tb^T}\n",
    "\\newcommand{\\Tb}{\\mathbf{T}}\n",
    "\\newcommand{\\Tt}{\\Tb^T}\n",
    "\\newcommand{\\ub}{\\mathbf{u}}\n",
    "\\newcommand{\\Ub}{\\mathbf{U}}\n",
    "\\newcommand{\\Ut}{\\Ub^T}\n",
    "\\newcommand{\\vb}{\\mathbf{v}}\n",
    "\\newcommand{\\Vb}{\\mathbf{V}}\n",
    "\\newcommand{\\wb}{\\mathbf{w}}\n",
    "\\newcommand{\\wnr}[1]{\\wb^{(\\text{#1})}}\n",
    "\\newcommand{\\wt}{\\wb^T}\n",
    "\\newcommand{\\Wb}{\\mathbf{W}}\n",
    "\\newcommand{\\Wt}{\\Wb^T}\n",
    "\\newcommand{\\Wtilde}{\\widetilde{\\Wb}}\n",
    "\\newcommand{\\Wtildet}{\\Wtilde^T}\n",
    "\\newcommand{\\Xb}{\\mathbf{X}}\n",
    "\\newcommand{\\Xt}{\\Xb^T}\n",
    "\\newcommand{\\Xtilde}{\\widetilde{\\Xb}}\n",
    "\\newcommand{\\Xtildet}{\\Xtilde^T}\n",
    "\\newcommand{\\xb}{\\mathbf{x}}\n",
    "\\newcommand{\\xt}{\\xb^T}\n",
    "\\newcommand{\\xtilde}{\\widetilde{\\xb}}\n",
    "\\newcommand{\\xtilden}{\\xtilde_n}\n",
    "\\newcommand{\\xtildent}{\\xtilden^T}\n",
    "\\newcommand{\\xp}{x^{\\prime}}\n",
    "\\newcommand{\\xbp}{\\xb^{\\prime}}\n",
    "\\newcommand{\\xbm}{\\xb_m}\n",
    "\\newcommand{\\xbn}{\\xb_n}\n",
    "\\newcommand{\\xbnp}{\\xb_{N+1}}\n",
    "\\newcommand{\\xab}{\\mathbf{x_a}}\n",
    "\\newcommand{\\xabt}{\\mathbf{x_a}^T}\n",
    "\\newcommand{\\xbb}{\\mathbf{x_b}}\n",
    "\\newcommand{\\xbbt}{\\mathbf{x_b}^T}\n",
    "\\newcommand{\\yb}{\\mathbf{y}}\n",
    "\\newcommand{\\yt}{\\yb^T}\n",
    "\\newcommand{\\yx}{y(\\xb)}\n",
    "\\newcommand{\\zb}{\\mathbf{z}}\n",
    "\\newcommand{\\zt}{\\zb^T}\n",
    "\\newcommand{\\zbm}{\\zb_m}\n",
    "\\newcommand{\\zbn}{\\zb_n}\n",
    "\\newcommand{\\zbnp}{\\zb_{n-1}}\n",
    "\\newcommand{\\znk}{\\zb_{nk}}\n",
    "\\newcommand{\\znpj}{\\zb_{n-1,j}}\n",
    "\\newcommand{\\Zb}{\\mathbf{Z}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "math shortcuts\n",
    "$\n",
    "\\newcommand{\\chib}{\\boldsymbol{\\chi}}\n",
    "\\newcommand{\\etab}{\\pmb{\\eta}}\n",
    "\\newcommand{\\etat}{\\eta^T}\n",
    "\\newcommand{\\etabt}{\\etab^T}\n",
    "\\newcommand{\\Lambdab}{\\pmb{\\Lambda}}\n",
    "\\newcommand{\\laa}{\\Lambda_{aa}}\n",
    "\\newcommand{\\laai}{\\Lambda_{aa}^{-1}}\n",
    "\\newcommand{\\lab}{\\Lambda_{ab}}\n",
    "\\newcommand{\\lba}{\\Lambda_{ba}}\n",
    "\\newcommand{\\lbb}{\\Lambda_{bb}}\n",
    "\\newcommand{\\lbbi}{\\Lambda_{bb}^{-1}}\n",
    "\\newcommand{\\li}{\\Lambda^{-1}}\n",
    "\\newcommand{\\Li}{\\Lambda^{-1}}\n",
    "\\newcommand{\\mub}{\\pmb{\\mu}}\n",
    "\\newcommand{\\mut}{\\mub^T}\n",
    "\\newcommand{\\muab}{\\pmb{\\mu}_a}\n",
    "\\newcommand{\\mubb}{\\pmb{\\mu}_b}\n",
    "\\newcommand{\\Phib}{\\pmb{\\Phi}}\n",
    "\\newcommand{\\Phibt}{\\Phib^T}\n",
    "\\newcommand{\\pib}{\\pmb{\\pi}}\n",
    "\\newcommand{\\sigmasqr}{\\sigma^2}\n",
    "\\newcommand{\\saa}{\\Sigma_{aa}}\n",
    "\\newcommand{\\sab}{\\Sigma_{ab}}\n",
    "\\newcommand{\\sba}{\\Sigma_{ba}}\n",
    "\\newcommand{\\sbb}{\\Sigma_{bb}}\n",
    "\\newcommand{\\Sigmai}{\\inv{\\Sigma}}\n",
    "\\newcommand{\\thetab}{\\pmb{\\theta}}\n",
    "\\newcommand{\\thetat}{\\thetab^T}\n",
    "\\newcommand{\\thetabh}{\\hat{\\thetab}}\n",
    "\\newcommand{\\thetaold}{\\thetab^{\\text{old}}}\n",
    "$\n",
    "$\n",
    "\\newcommand{\\zerob}{\\pmb{0}}\n",
    "\\newcommand{\\ed}{\\mathbb{E}_{\\D}}\n",
    "\\newcommand{\\edyx}{\\ed\\left[y(\\xb ; \\D)\\right]}\n",
    "\\newcommand{\\dx}{~dx}\n",
    "\\newcommand{\\dxb}{~d\\xb}\n",
    "\\newcommand{\\pxdxb}{p(\\xb) \\dxb}\n",
    "\\newcommand{\\dwb}{~d\\wb}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aliases for distributions\n",
    "$\\newcommand{\\multivarcoeff}{\\frac{1}{(2\\pi)^{D/2}}\n",
    "\\frac{1}{\\left| \\mathbf{\\Sigma}\\right|^{1/2}}}$\n",
    "$\\newcommand{\\multivarexp}[2]\n",
    "{\n",
    "\\left\\{\n",
    " -\\frac{1}{2} \n",
    " {#1}^T \n",
    " #2\n",
    " {#1}\n",
    "\\right\\}\n",
    "}$\n",
    "$\\newcommand{\\multivarexpx}[1]{\\multivarexp{#1}{\\Sigma^{-1}}}$\n",
    "$\\newcommand{\\multivarexpstd}{\\multivarexpx{(\\xb-\\mub)}}$\n",
    "$\\newcommand{\\gam}{\\operatorname{Gam}}$\n",
    "$\n",
    "\\newcommand{\\Nl}[3]{\\mathcal{N}\\left(#1 \\mid #2, #3\\right)}\n",
    "\\newcommand{\\Nstdx}{\\Nl{\\mathbf{x}}{\\mathbf{\\mu}}{\\Sigma}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than fixing the covariance, the parameters for the covariance can be inferred from the data.\n",
    "\n",
    "These parameters govern things like\n",
    "* length-scale of the correlations\n",
    "* precision of the noise\n",
    "\n",
    "and as such correspond to the hyperparametrs of the standard parametric model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to evaluate the likelihood function $p(\\tb \\mid \\thetab)$ where $\\thetab$ denotes the hyperparameters of the GP model.  \n",
    "\n",
    "simplest approach is to make a point estimate of $\\thetab$ by maximizing the log likelihood function.\n",
    "\n",
    "since $\\thetab$ represents the set of hyperparameters of the regressoin problem, this is analogous to type 2 ML for linear regression.\n",
    "\n",
    "Maximizatio of the log likelihood can be done using efficient gradient-based optimization algos such as conjugate gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the mean of the marginal is \n",
    "$\\Nl{t}{\\Ab \\mub + \\bb}{\\Lbi + \\Ab \\Li \\At}$, we have\n",
    "\n",
    "$$\n",
    "p(\\tb) = \\Nl{\\tb}{\\zerob}{\\inv{\\beta}\\I_N + \\Kb}\n",
    "= \\Nl{\\tb}{\\zerob}{\\Cb}\n",
    "$$\n",
    "\n",
    "where the covariance is\n",
    "$$\n",
    "\\Cb(\\xbn, \\xbm) = \\inv{\\beta} \\delta_{nm} + \\kappa(\\xbn, \\xbm)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the log likelihood is then\n",
    "$$\n",
    "\\ln p(\\tb \\mid \\thetab)\n",
    "=\n",
    "-\\half \\ln \\Mod{\\Cn}\n",
    "-\\half \\tt \\inv{\\Cn} \\tb\n",
    "-\\frachalf{N} \\ln(2\\pi)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the first term is the complexity penalty term\n",
    "* The second term a negative quadratic, and plays the role of a data-fit measure\n",
    "* The third term is a log normalization term, independent of the data, and not very interesting\n",
    "\n",
    "from \\citeme{Gaussian Processes in Machine Learning - Carl Edward Rasmussen}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remember\n",
    "$$\n",
    "\\arrthree{\n",
    "\\Partial{}{x} \\Mod{\\Ab} &= \\trace{ \\inv{\\Ab} \\Partial{\\Ab}{x}}\n",
    "\\\\\n",
    "\\Partial{}{x} \\inv{\\Ab} &= -\\inv{\\Ab} \\Partial{\\Ab}{x} \\inv{\\Ab}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arrthree{\n",
    "\\Partial{}{\\xb} (\\Ab \\Ai)\n",
    "&=\n",
    "\\Partial{\\Ab}{\\xb}\\Ai  + \\Ab \\Partial{\\Ai}{\\xb} = 0\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus\n",
    "$$\n",
    "\\Partial{}{\\theta_i} \\ln p(\\tb \\mid \\thetab)\n",
    "=\n",
    "-\\half \\trace{\\inv{\\Cn} \\Partial{\\Cn}{\\theta_i}}\n",
    "+ \\half \\tt \\inv{\\Cn} \\Partial{\\Cn}{\\theta_i} \\inv{\\Cn} \\tb\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because $\\ln p(\\tb \\mid \\thetab)$ will in general be a nonconvex function, it can have multiple maxima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is straightforward to introduce a prior over **θ** and to maximize the log posterior using gradient-based methods. In a fully Bayesian treatment, we need to evaluate marginals over **θ** weighted by the product of the prior p(**θ**) and the likelihood function p(**t**|**θ**). In general, however, exact marginalization will be intractable, and we\n",
    "must resort to approximations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - cg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seek the minimum value of the expression\n",
    "$au^2 + buv + cv^2 + du + ev + f$ for given values of the parameters and an initial guess (u, v) = (0, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.617021\n",
      "         Iterations: 2\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "res1 =  [-1.80851064 -0.25531915]\n"
     ]
    }
   ],
   "source": [
    "args = (2, 3, 7, 8, 9, 10)  # parameter values\n",
    "\n",
    "def f(x, *args):\n",
    "    u, v = x\n",
    "    a, b, c, d, e, f = args\n",
    "    return a*u**2 + b*u*v + c*v**2 + d*u + e*v + f\n",
    "\n",
    "def gradf(x, *args):\n",
    "    u, v = x\n",
    "    a, b, c, d, e, f = args\n",
    "    gu = 2*a*u + b*v + d\t # u-component of the gradient\n",
    "    gv = b*u + 2*c*v + e\t # v-component of the gradient\n",
    "    return np.asarray((gu, gv))\n",
    "\n",
    "x0 = np.asarray((0, 0))\t # Initial guess.\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "res1 = optimize.fmin_cg(f, x0, fprime=gradf, args=args)\n",
    "\n",
    "print('res1 = ', res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\ln p(\\tb \\mid \\thetab)\n",
    "=\n",
    "-\\half \\ln \\Mod{\\Cn}\n",
    "-\\half \\tt \\inv{\\Cn} \\tb\n",
    "-\\frachalf{N} \\ln(2\\pi)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arrthree{\n",
    "\\Partial{}{\\theta_i} \\ln p(\\tb \\mid \\thetab)\n",
    "&=\n",
    "-\\half \\trace{\\inv{\\Cn} \\Partial{\\Cn}{\\theta_i}}\n",
    "+ \\half \\tt \\inv{\\Cn} \\Partial{\\Cn}{\\theta_i} \\inv{\\Cn} \\tb\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the rbf kernel with just the length-scale parameter $\\sigma$\n",
    "\n",
    "$$\n",
    "\\Cb_{n,m} = \\kappa(\\xbn, \\xbm) =\n",
    "\\expb{-\\frac{\\Norm{\\xbn-\\xbm}^2}{2\\sigma^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arrthree{\n",
    "\\Partial{}{\\sigma} \\Cb_{n,m}\n",
    "&=\n",
    "\\expb{-\\frac{\\Norm{\\xbn-\\xbm}^2}{2\\sigma^2}}\n",
    " ~\\frac{\\Norm{\\xbn-\\xbm}^2}{\\sigma^3}\n",
    "\\\\ &\n",
    "=\n",
    "\\Bracket{\\expb{-\\frac{\\Norm{\\xbn-\\xbm}^2}{2}}}^{(1/\\sigma^2)}\n",
    "~\\Norm{\\xbn-\\xbm}^2 ~\\fracrec{\\sigma^3}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\arrthree{\n",
    "A_{n,m} &= \\expb{-\\frac{\\Norm{\\xbn-\\xbm}^2}{2}} \\\\\n",
    "B_{n,m} &= \\Norm{\\xbn - \\xbm}^2 \\\\\n",
    "Ci &= \\inv{\\Cn}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: construct f-partial and pass it to CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sin():\n",
    "    thetas = np.linspace(0,2*math.pi,100)\n",
    "    plt.plot(thetas, np.sin(thetas), 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_samples(in_pts, betai=1.0):\n",
    "    x = np.random.rand(in_pts).reshape(-1,1)*2*math.pi\n",
    "    if betai==0.0:\n",
    "        y_noise = np.zeros_like(x)\n",
    "    else:\n",
    "        y_noise = np.random.normal(0, betai, size=(in_pts,1))\n",
    "    y = np.sin(x) + y_noise\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kernel_1(x1, y1, sigma):\n",
    "    exponent = -((x1-y1)**2)/(2.*sigma**2)\n",
    "    return math.e**exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gp_covar(xgt, tgt, betai, sigma):\n",
    "    n = xgt.shape[0]\n",
    "    covar = np.zeros((n,n))\n",
    "    for ix in range(n):\n",
    "        for iy in range(ix+1, n):\n",
    "            val = kernel_1(xgt[ix], xgt[iy], sigma)\n",
    "            covar[ix, iy] = covar[iy, ix] = val\n",
    "    return covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(xt, tt, cni, betai, x, sigma):\n",
    "    n = cni.shape[0]\n",
    "    k = np.array([kernel_1(xt[ix], x, sigma) for ix in range(n)])\n",
    "    k = k.reshape(-1,1)\n",
    "    mean1 = k.T @ cni @ tt\n",
    "    c = kernel_1(x, x, sigma) + betai\n",
    "    covar1 = c - k.T @ cni @ k\n",
    "    return [mean1, covar1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      " [[0 1]\n",
      " [2 3]]\n",
      "[[ 1.          0.60653066]\n",
      " [ 0.36787944  0.22313016]]\n",
      "[1.0, 0.6065306597126334, 0.36787944117144233, 0.22313016014842985]\n"
     ]
    }
   ],
   "source": [
    "# testing correctness of computing \\Cb\n",
    "A = np.array([[0,1],[2,3]])\n",
    "print('A\\n', A)\n",
    "print(np.exp(-A)**(1/2.))\n",
    "print([math.e**(-aa/2.) for aa in range(4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\ln p(\\tb \\mid \\thetab)\n",
    "=\n",
    "-\\half \\ln \\Mod{\\Cn}\n",
    "-\\half \\tt \\inv{\\Cn} \\tb\n",
    "-\\frachalf{N} \\ln(2\\pi)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the rbf kernel with just the length-scale parameter $\\sigma$\n",
    "\n",
    "$$\n",
    "\\Cb_{n,m} = \\kappa(\\xbn, \\xbm) =\n",
    "\\expb{-\\frac{\\Norm{\\xbn-\\xbm}^2}{2\\sigma^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CG is for minimizing and we have to maximize the likelihood.  \n",
    "hence we have to take negative log likelihood, which explains the negative sign in the return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(sigma, *args):\n",
    "    A, B, t, N = args\n",
    "    C = A**(1./(sigma**2)) + np.eye(N)*1e-6\n",
    "    Ci = np.linalg.inv(C)\n",
    "    Cd = np.linalg.det(C)\n",
    "    term1 = -0.5 * math.log(Cd)\n",
    "    term2 = -0.5 * t.T @ Ci @ t \n",
    "    term3 = -N/2. * math.log(2*math.pi)\n",
    "    return -(term1 + term2 + term3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_sigma_min(x, t, N):\n",
    "    B = np.square(x - x.T)\n",
    "    A = np.exp( - B/2.)\n",
    "    res1 = optimize.fmin_cg(f, (1.), args=(A, B, t, N))\n",
    "    print('sigma optimal = ', res1[0])\n",
    "    return res1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_covar(x, mu, varr):\n",
    "    n = x.shape[0]\n",
    "    for ix in range(n):\n",
    "        xx = x[ix]\n",
    "        m, v = mu[ix], varr[ix]\n",
    "        plt.plot((xx,xx),(m-v,m+v), color=(248/255., 163/255., 211/255.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -306.572883\n",
      "         Iterations: 0\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 23\n",
      "sigma optimal =  1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b97d66198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_gp_reg>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_gp_reg(in_pts = 65, betai=0.0, test_max= 2*math.pi):\n",
    "    xgt, tgt = draw_samples(in_pts, betai)\n",
    "    sigma = find_sigma_min(xgt, tgt, in_pts)\n",
    "    cn = get_gp_covar(xgt, tgt, betai, sigma)\n",
    "    cn = cn + 1e-6*np.eye(in_pts)\n",
    "    cni = np.linalg.inv(cn)\n",
    "    x_test = np.linspace(0,test_max,100)\n",
    "    t_test = np.array([get_predictions(xgt, tgt, cni, betai, xx, sigma) \n",
    "                       for xx in x_test])\n",
    "    t_test = t_test.reshape(-1, 2)\n",
    "    plot_sin()\n",
    "    plt.plot(xgt, tgt, '.b')\n",
    "    plt.plot(x_test, t_test[:,0])\n",
    "    plot_covar(x_test, t_test[:,0], t_test[:,1])\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_gp_reg,\n",
    "         in_pts=(2, 100, 1),\n",
    "         betai=(0,5.0,0.1),\n",
    "         test_max=(math.pi, 4*math.pi, 0.1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sexy part is that the uncertainty is quite high where we haven't data and is low in the neighborhood of data.  \n",
    "thats brings us to the second problem, why does this happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma^2(\\xbnp) = c - \\kt \\inv{\\Cn} \\kb\n",
    "$$\n",
    "\n",
    "The second term is very negative in the regions of data since $\\kt \\inv{\\Cn} \\kb$ is high, which brings down the uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -67.789523\n",
      "         Iterations: 1\n",
      "         Function evaluations: 33\n",
      "         Gradient evaluations: 11\n",
      "res1 =  [  7.97866602e-06]\n"
     ]
    }
   ],
   "source": [
    "N=35\n",
    "x,t = draw_samples(N)\n",
    "B = np.square(x - x.T)\n",
    "A = np.exp( - B/2.)\n",
    "#print(x.shape, t.shape, A.shape, B.shape)\n",
    "#f(1., *(A, B, t, N))\n",
    "res1 = optimize.fmin_cg(f, (1.), args=(A, B, t, N))\n",
    "print('res1 = ', res1)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
